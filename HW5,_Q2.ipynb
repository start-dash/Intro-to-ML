{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9do472xIzOBkzdEC0XbDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/start-dash/Intro-to-ML/blob/main/HW5%2C_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHpTV3QhrVsB"
      },
      "outputs": [],
      "source": [
        "# 2a. Develop preprocessing and a training loop to train a linear regression model that predicts housing price based on the following input variables:\n",
        "# area, bedrooms, bathrooms, stories, parking\n",
        "# For this, you need to use the housing dataset. For training and validation, use 80% (training) and 20% (validation) split. Identify the best parameters for your\n",
        "# regression model based on the above input variables. in this case you will have 6 parameters.\n",
        "# 2b. Use 5000 epochs for your training. Explore different learning rates from 0.1 to 0.0001 (you need 4 separate trainings).\n",
        "# Report your loss and validation accuracy for every 500 epochs per training. Pick the best linear model.\n",
        "# 2c. Compare your results against the linear regression done in HW 1. Do you see meaningful differences?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "# Create a classifier\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#Creating an SVM classifier\n",
        "from sklearn import svm\n",
        "# \"Linear Support vector classifier\"\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA as RandomizedPCA\n",
        "\n",
        "#As an example of support vector machines in action, let's take a look at the facial recognition problem.\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# use seaborn plotting defaults\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from ipywidgets import interact, fixed\n",
        "#let's look at some data that is not linearly separable:\n",
        "from sklearn.datasets import make_circles\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#Finally, we can use a grid search cross-validation to explore combinations of parameters.\n",
        "#Here we will adjust C (which controls the margin hardness)\n",
        "#We also explore gamma (which controls the size of the radial basis function kernel)\n",
        "#and determine the best model:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# For better accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# Evaluate the model using evaluation metrics: Accuracy, precision, and recall.\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.cluster import SpectralClustering\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "zbgcjpFCp7lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read URL"
      ],
      "metadata": {
        "id": "4zB1YVbPqF3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/start-dash/Intro-to-ML/main/Datasets/Housing.csv\"\n",
        "housing = pd.read_csv(url)\n",
        "housing.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Ct28igE-pZJu",
        "outputId": "6803f74a-ad7a-469b-fec8-4d41812108b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
              "0  13300000  7420         4          2        3      yes        no       no   \n",
              "1  12250000  8960         4          4        4      yes        no       no   \n",
              "2  12250000  9960         3          2        2      yes        no      yes   \n",
              "3  12215000  7500         4          2        2      yes        no      yes   \n",
              "4  11410000  7420         4          1        2      yes       yes      yes   \n",
              "\n",
              "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
              "0              no             yes        2      yes        furnished  \n",
              "1              no             yes        3       no        furnished  \n",
              "2              no              no        2      yes   semi-furnished  \n",
              "3              no             yes        3      yes        furnished  \n",
              "4              no             yes        2       no        furnished  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cee2a20-dbdb-45e9-ab4d-3e6754ccff9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>area</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>stories</th>\n",
              "      <th>mainroad</th>\n",
              "      <th>guestroom</th>\n",
              "      <th>basement</th>\n",
              "      <th>hotwaterheating</th>\n",
              "      <th>airconditioning</th>\n",
              "      <th>parking</th>\n",
              "      <th>prefarea</th>\n",
              "      <th>furnishingstatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13300000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12250000</td>\n",
              "      <td>8960</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12250000</td>\n",
              "      <td>9960</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>semi-furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12215000</td>\n",
              "      <td>7500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11410000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cee2a20-dbdb-45e9-ab4d-3e6754ccff9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cee2a20-dbdb-45e9-ab4d-3e6754ccff9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cee2a20-dbdb-45e9-ab4d-3e6754ccff9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fced7836-4906-47c9-9f20-93b731d3906a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fced7836-4906-47c9-9f20-93b731d3906a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fced7836-4906-47c9-9f20-93b731d3906a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables Mapping"
      ],
      "metadata": {
        "id": "n3Cqi-2DqGVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables to map\n",
        "\n",
        "varlist = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
        "\n",
        "y = housing.pop('price')\n",
        "x = housing[varlist].values\n",
        "\n",
        "t_u = torch.tensor(x, dtype=torch.float32)\n",
        "t_un = torch.tensor(StandardScaler().fit_transform(x), dtype=torch.float32)\n",
        "t_c = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "aHBGnSvjqFiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_un.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_t_u = t_u[train_indices]\n",
        "train_t_un = t_un[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_un = t_un[val_indices]\n",
        "val_t_c = t_c[val_indices]"
      ],
      "metadata": {
        "id": "u72l7-c4sNHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lin_model(t_u, w5, w4, w3, w2, w1, b):\n",
        "  return torch.matmul(t_u, params[:-1]) + params[-1]\n",
        "\n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()\n",
        "\n",
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  training_losses = []\n",
        "  valid_losses = []\n",
        "\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    train_t_p = lin_model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    val_t_p = lin_model(val_t_u, *params)\n",
        "    val_loss = loss_fn(val_t_p, val_t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    training_losses.append(train_loss)\n",
        "    valid_losses.append(val_loss)\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch {epoch}, Training Loss {train_loss.item():.4f}, Validation Loss {val_loss.item():.4f}')\n",
        "  return params, train_loss, val_loss"
      ],
      "metadata": {
        "id": "9X2qU1SxOlR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD Optimized"
      ],
      "metadata": {
        "id": "b9-WmC-9OaMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.sgd import SGD\n",
        "learning_rate = [0.1, 0.01, 0.001, 0.0001]\n",
        "for lr in learning_rate:\n",
        "  params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "  optimizerSGD_linear = optim.SGD([params], lr = lr)\n",
        "  print(f'Training with learning rate: {lr}')\n",
        "  training_loop(\n",
        "      n_epochs = 5000,\n",
        "      optimizer=optimizerSGD_linear,\n",
        "      params = params,\n",
        "      train_t_u = train_t_un,\n",
        "      val_t_u = val_t_un,\n",
        "      train_t_c = train_t_c,\n",
        "      val_t_c = val_t_c\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWl4HORvObs2",
        "outputId": "03d3d815-589b-4deb-cf0c-c5c9e3c9e391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with learning rate: 0.1\n",
            "Epoch 500, Training Loss nan, Validation Loss nan\n",
            "Epoch 1000, Training Loss nan, Validation Loss nan\n",
            "Epoch 1500, Training Loss nan, Validation Loss nan\n",
            "Epoch 2000, Training Loss nan, Validation Loss nan\n",
            "Epoch 2500, Training Loss nan, Validation Loss nan\n",
            "Epoch 3000, Training Loss nan, Validation Loss nan\n",
            "Epoch 3500, Training Loss nan, Validation Loss nan\n",
            "Epoch 4000, Training Loss nan, Validation Loss nan\n",
            "Epoch 4500, Training Loss nan, Validation Loss nan\n",
            "Epoch 5000, Training Loss nan, Validation Loss nan\n",
            "Training with learning rate: 0.01\n",
            "Epoch 500, Training Loss nan, Validation Loss nan\n",
            "Epoch 1000, Training Loss nan, Validation Loss nan\n",
            "Epoch 1500, Training Loss nan, Validation Loss nan\n",
            "Epoch 2000, Training Loss nan, Validation Loss nan\n",
            "Epoch 2500, Training Loss nan, Validation Loss nan\n",
            "Epoch 3000, Training Loss nan, Validation Loss nan\n",
            "Epoch 3500, Training Loss nan, Validation Loss nan\n",
            "Epoch 4000, Training Loss nan, Validation Loss nan\n",
            "Epoch 4500, Training Loss nan, Validation Loss nan\n",
            "Epoch 5000, Training Loss nan, Validation Loss nan\n",
            "Training with learning rate: 0.001\n",
            "Epoch 500, Training Loss nan, Validation Loss nan\n",
            "Epoch 1000, Training Loss nan, Validation Loss nan\n",
            "Epoch 1500, Training Loss nan, Validation Loss nan\n",
            "Epoch 2000, Training Loss nan, Validation Loss nan\n",
            "Epoch 2500, Training Loss nan, Validation Loss nan\n",
            "Epoch 3000, Training Loss nan, Validation Loss nan\n",
            "Epoch 3500, Training Loss nan, Validation Loss nan\n",
            "Epoch 4000, Training Loss nan, Validation Loss nan\n",
            "Epoch 4500, Training Loss nan, Validation Loss nan\n",
            "Epoch 5000, Training Loss nan, Validation Loss nan\n",
            "Training with learning rate: 0.0001\n",
            "Epoch 500, Training Loss nan, Validation Loss nan\n",
            "Epoch 1000, Training Loss nan, Validation Loss nan\n",
            "Epoch 1500, Training Loss nan, Validation Loss nan\n",
            "Epoch 2000, Training Loss nan, Validation Loss nan\n",
            "Epoch 2500, Training Loss nan, Validation Loss nan\n",
            "Epoch 3000, Training Loss nan, Validation Loss nan\n",
            "Epoch 3500, Training Loss nan, Validation Loss nan\n",
            "Epoch 4000, Training Loss nan, Validation Loss nan\n",
            "Epoch 4500, Training Loss nan, Validation Loss nan\n",
            "Epoch 5000, Training Loss nan, Validation Loss nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store train and valid losses\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "optimizer = optim.SGD([params], lr = 0.1)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "SGD_trainLoss1 = np.array([item.detach().item() for item in trainLoss])\n",
        "SGD_validLoss1 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.SGD([params], lr = 0.01)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "SGD_trainLoss2 = np.array([item.detach().item() for item in trainLoss])\n",
        "SGD_validLoss2 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.SGD([params], lr = 0.001)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "SGD_trainLoss3 = np.array([item.detach().item() for item in trainLoss])\n",
        "SGD_validLoss3 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.SGD([params], lr = 0.0001)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "SGD_trainLoss4 = np.array([item.detach().item() for item in trainLoss])\n",
        "SGD_validLoss4 = np.array([item.detach().item() for item in validLoss])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "Y3Du7Uaibjuj",
        "outputId": "ec57004d-a866-490c-f70d-40e0763ec98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 1000, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 1500, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 2000, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 2500, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 3000, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 3500, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 4000, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 4500, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n",
            "Epoch 5000, Training Loss 1536919863296.0000, Validation Loss 1527499456512.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-47da1d5e155a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t_un\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_t_un\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_t_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mSGD_trainLoss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainLoss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mSGD_validLoss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidLoss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# See gh-54457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration over a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam Optimized"
      ],
      "metadata": {
        "id": "QS8Qtg8ePdVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.1, 0.01, 0.001, 0.0001]\n",
        "for lr in learning_rate:\n",
        "  params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "  optimizerADAM_linear = optim.Adam([params], lr = lr)\n",
        "  print(f'Training with learning rate: {lr}')\n",
        "  training_loop(\n",
        "        n_epochs = 5000,\n",
        "        optimizer=optimizerADAM_linear,\n",
        "        params = params,\n",
        "        train_t_u = train_t_un,\n",
        "        val_t_u = val_t_un,\n",
        "        train_t_c = train_t_c,\n",
        "        val_t_c = val_t_c\n",
        "    )"
      ],
      "metadata": {
        "id": "uvACRRFjvQb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dd5e2d-020c-4ead-f869-631e69944d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with learning rate: 0.1\n",
            "Epoch 500, Training Loss 25441865826304.0000, Validation Loss 27943126433792.0000\n",
            "Epoch 1000, Training Loss 25183358287872.0000, Validation Loss 27653780275200.0000\n",
            "Epoch 1500, Training Loss 24926891278336.0000, Validation Loss 27366707429376.0000\n",
            "Epoch 2000, Training Loss 24672355745792.0000, Validation Loss 27081777872896.0000\n",
            "Epoch 2500, Training Loss 24419646832640.0000, Validation Loss 26798888845312.0000\n",
            "Epoch 3000, Training Loss 24168699527168.0000, Validation Loss 26517950169088.0000\n",
            "Epoch 3500, Training Loss 23919444623360.0000, Validation Loss 26238886346752.0000\n",
            "Epoch 4000, Training Loss 23671821303808.0000, Validation Loss 25961636560896.0000\n",
            "Epoch 4500, Training Loss 23425812791296.0000, Validation Loss 25686179840000.0000\n",
            "Epoch 5000, Training Loss 23181379239936.0000, Validation Loss 25412467949568.0000\n",
            "Training with learning rate: 0.01\n",
            "Epoch 500, Training Loss 25675912183808.0000, Validation Loss 28205069107200.0000\n",
            "Epoch 1000, Training Loss 25649769086976.0000, Validation Loss 28175807545344.0000\n",
            "Epoch 1500, Training Loss 25623646961664.0000, Validation Loss 28146569052160.0000\n",
            "Epoch 2000, Training Loss 25597537419264.0000, Validation Loss 28117353627648.0000\n",
            "Epoch 2500, Training Loss 25571453042688.0000, Validation Loss 28088154980352.0000\n",
            "Epoch 3000, Training Loss 25545383346176.0000, Validation Loss 28058979401728.0000\n",
            "Epoch 3500, Training Loss 25519328329728.0000, Validation Loss 28029818503168.0000\n",
            "Epoch 4000, Training Loss 25493290090496.0000, Validation Loss 28000676478976.0000\n",
            "Epoch 4500, Training Loss 25467266531328.0000, Validation Loss 27971551232000.0000\n",
            "Epoch 5000, Training Loss 25441268137984.0000, Validation Loss 27942446956544.0000\n",
            "Training with learning rate: 0.001\n",
            "Epoch 500, Training Loss 25699414966272.0000, Validation Loss 28231371587584.0000\n",
            "Epoch 1000, Training Loss 25696799817728.0000, Validation Loss 28228441866240.0000\n",
            "Epoch 1500, Training Loss 25694180474880.0000, Validation Loss 28225510047744.0000\n",
            "Epoch 2000, Training Loss 25691563229184.0000, Validation Loss 28222584520704.0000\n",
            "Epoch 2500, Training Loss 25688948080640.0000, Validation Loss 28219656896512.0000\n",
            "Epoch 3000, Training Loss 25686330834944.0000, Validation Loss 28216725078016.0000\n",
            "Epoch 3500, Training Loss 25683715686400.0000, Validation Loss 28213797453824.0000\n",
            "Epoch 4000, Training Loss 25681096343552.0000, Validation Loss 28210869829632.0000\n",
            "Epoch 4500, Training Loss 25678479097856.0000, Validation Loss 28207938011136.0000\n",
            "Epoch 5000, Training Loss 25675866046464.0000, Validation Loss 28205010386944.0000\n",
            "Training with learning rate: 0.0001\n",
            "Epoch 500, Training Loss 25701765873664.0000, Validation Loss 28234001416192.0000\n",
            "Epoch 1000, Training Loss 25701505826816.0000, Validation Loss 28233707814912.0000\n",
            "Epoch 1500, Training Loss 25701241585664.0000, Validation Loss 28233418407936.0000\n",
            "Epoch 2000, Training Loss 25700981538816.0000, Validation Loss 28233122709504.0000\n",
            "Epoch 2500, Training Loss 25700719394816.0000, Validation Loss 28232831205376.0000\n",
            "Epoch 3000, Training Loss 25700459347968.0000, Validation Loss 28232535506944.0000\n",
            "Epoch 3500, Training Loss 25700195106816.0000, Validation Loss 28232244002816.0000\n",
            "Epoch 4000, Training Loss 25699930865664.0000, Validation Loss 28231952498688.0000\n",
            "Epoch 4500, Training Loss 25699672915968.0000, Validation Loss 28231656800256.0000\n",
            "Epoch 5000, Training Loss 25699408674816.0000, Validation Loss 28231367393280.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store train and valid losses\n",
        "optimizer = optim.Adam([params], lr = 0.1)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "ADAM_trainLoss1 = np.array([item.detach().item() for item in trainLoss])\n",
        "ADAM_validLoss1 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.Adam([params], lr = 0.01)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "ADAM_trainLoss2 = np.array([item.detach().item() for item in trainLoss])\n",
        "ADAM_validLoss2 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.Adam([params], lr = 0.001)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "ADAM_trainLoss3 = np.array([item.detach().item() for item in trainLoss])\n",
        "ADAM_validLoss3 = np.array([item.detach().item() for item in validLoss])\n",
        "\n",
        "optimizer = optim.Adam([params], lr = 0.0001)\n",
        "\n",
        "model, trainLoss, validLoss = training_loop(5000, optimizer, params, train_t_un, val_t_un, train_t_c, val_t_c)\n",
        "ADAM_trainLoss4 = np.array([item.detach().item() for item in trainLoss])\n",
        "ADAM_validLoss4 = np.array([item.detach().item() for item in validLoss])"
      ],
      "metadata": {
        "id": "Klkreso_bLsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression Loss Plots"
      ],
      "metadata": {
        "id": "DswZ1ZS9QW14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Optimized\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.suptitle(\"SGD Optimized Linear Regression Loss w/ 5 Inputs\")\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(SGD_trainLoss1, color='black')\n",
        "plt.plot(SGD_validLoss1, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.1')\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(SGD_trainLoss2, color='black')\n",
        "plt.plot(SGD_validLoss2, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.01')\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(SGD_trainLoss3, color='black')\n",
        "plt.plot(SGD_validLoss3, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.001')\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(SGD_trainLoss3, color='black')\n",
        "plt.plot(SGD_validLoss3, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.0001')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "YPweoNM1TnWN",
        "outputId": "f14d84cd-c7f3-40a3-f3d8-355fd1ef4de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-481c48fc8544>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD_trainLoss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD_validLoss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss with Learning Rate of 1e-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SGD_trainLoss1' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam Optimized\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.suptitle(\"Adam Optimized Linear Regression Loss w/ 5 Inputs\")\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(ADAM_trainLoss1, color='black')\n",
        "plt.plot(ADAM_validLoss1, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.1')\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(ADAM_trainLoss2, color='black')\n",
        "plt.plot(ADAM_validLoss2, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.01')\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(ADAM_trainLoss3, color='black')\n",
        "plt.plot(ADAM_validLoss3, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.001')\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(ADAM_trainLoss3, color='black')\n",
        "plt.plot(ADAM_validLoss3, color='red')\n",
        "plt.title('Loss w/ Learning Rate of 0.0001')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dqp3VRIpiayO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}